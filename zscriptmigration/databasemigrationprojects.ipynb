{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a8dac8a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from dotenv import load_dotenv\n",
    "from urllib.parse import quote_plus\n",
    "from bs4 import BeautifulSoup, Comment, Doctype\n",
    "import re\n",
    "import time \n",
    "\n",
    "\n",
    "# Cargar variables de entorno (tu GOOGLE_API_KEY desde el archivo .env)\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "929e167f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credenciales de la Base de Datos ANTIGUA (le√≠das de tu descripci√≥n)\n",
    "DB_OLD_USER = \"root\"\n",
    "DB_OLD_PASS = \"\" # Sin contrase√±a\n",
    "DB_OLD_HOST = \"127.0.0.1\"\n",
    "DB_OLD_NAME = \"sai_v2\"\n",
    "\n",
    "# Credenciales de la Base de Datos NUEVA (le√≠das de tu descripci√≥n)\n",
    "DB_NEW_USER = \"root\"\n",
    "DB_NEW_PASS = \"\" # Sin contrase√±a\n",
    "DB_NEW_HOST = \"127.0.0.1\"\n",
    "DB_NEW_NAME = \"sai_v5\"\n",
    "\n",
    "endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "STATIC_CONTENT_STRUCTURE = {\n",
    "    \"en\": {\n",
    "        \"special_tag\": \"Urgent Help\",\n",
    "        'description_heading'    : 'Description Heading',\n",
    "        'description_text'       : 'Detailed Description',\n",
    "        'summary_title'          : 'Summary Title',\n",
    "        'summary_text'           : 'Summary Text',\n",
    "        'help_mini_title'        : \"Help People In need\",\n",
    "        'help_title'             : \"Start Donating Today, Make The Difference\",\n",
    "        'help_btn_text'          : \"DONATE TO THIS PROJECT >\"\n",
    "    },\n",
    "    \"es\": {\n",
    "        \"special_tag\": \"Ayuda urgente\",\n",
    "        \"description_heading\": \"Subtitulo por defecto\",\n",
    "        \"description_text\": \"Texto de descripci√≥n por defecto\",\n",
    "        'summary_title': 'Titulo de resumen',\n",
    "        \"summary_text\": \"Texto de resumen\",\n",
    "        'help_mini_title': \"Ayuda a personas en necesidad\",\n",
    "        'help_title': \"Comienza a donar hoy, Haz la diferencia\",\n",
    "        'help_btn_text': \"DONAR A ESTE PROYECTO >\"\n",
    "    }\n",
    "}\n",
    "\n",
    "STATIC_CONTENT_JSON = json.dumps(STATIC_CONTENT_STRUCTURE, ensure_ascii=False)\n",
    "\n",
    "with open(\"promptproject2.txt\", 'r', encoding='utf-8') as f:\n",
    "    system_prompt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "652579fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- FUNCIONES AUXILIARES ---\n",
    "\n",
    "def call_azure_openai(system_prompt, user_message, max_retries=5):\n",
    "    \"\"\"Env√≠a una solicitud a Azure OpenAI y maneja errores 429 con reintentos.\"\"\"\n",
    "    endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "    if not endpoint or not api_key:\n",
    "        print(\"‚ùå Faltan credenciales de Azure OpenAI\")\n",
    "        return None\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"api-key\": api_key\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_message}\n",
    "        ],\n",
    "        \"max_tokens\": 4000,\n",
    "        \"temperature\": 0.3,\n",
    "        \"top_p\": 0.95,\n",
    "        \"frequency_penalty\": 0.5,\n",
    "        \"presence_penalty\": 0.5\n",
    "    }\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = requests.post(endpoint, headers=headers, json=payload, timeout=60)\n",
    "\n",
    "            if response.status_code == 429:\n",
    "                # Si Azure devuelve un retry-after personalizado, lo usamos\n",
    "                retry_after = response.headers.get(\"Retry-After\")\n",
    "                wait_time = int(retry_after) if retry_after else 2 ** attempt\n",
    "                print(f\"üîÅ Esperando {wait_time} segundos por l√≠mite de tasa (429)...\")\n",
    "                time.sleep(wait_time)\n",
    "                continue\n",
    "\n",
    "            if response.status_code != 200:\n",
    "                print(f\"‚ùå Error {response.status_code}: {response.text}\")\n",
    "                return None\n",
    "\n",
    "            return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"‚ùå Error en la solicitud: {e}\")\n",
    "            return None\n",
    "        except (KeyError, IndexError, json.JSONDecodeError) as e:\n",
    "            print(f\"‚ùå Error procesando respuesta: {e}\")\n",
    "            return None\n",
    "\n",
    "    print(\"‚ùå Se excedieron los reintentos por error 429.\")\n",
    "    return None\n",
    "\n",
    "def clean_html(html_content):\n",
    "    \"\"\"Funci√≥n principal de limpieza con truncamiento opcional\"\"\"\n",
    "    simplified = simplify_html(html_content)\n",
    "    \n",
    "    # Truncar si es necesario despu√©s de simplificar\n",
    "    MAX_LENGTH = 10000  # Menor que antes porque el HTML ahora es m√°s simple\n",
    "    if len(simplified) > MAX_LENGTH:\n",
    "        # Truncar de manera inteligente manteniendo estructura\n",
    "        soup = BeautifulSoup(simplified, 'html.parser')\n",
    "        text = soup.get_text()[:MAX_LENGTH]\n",
    "        return text + \" [CONTENIDO TRUNCADO]\"\n",
    "    \n",
    "    return simplified\n",
    "\n",
    "def simplify_html(html_content):\n",
    "    \"\"\"\n",
    "    Simplifica el HTML eliminando:\n",
    "    - Estilos (style, class, id)\n",
    "    - Scripts y metadatos\n",
    "    - Comentarios y doctypes\n",
    "    - Atributos innecesarios\n",
    "    - Conserva solo estructura b√°sica y contenido\n",
    "    \"\"\"\n",
    "    if not html_content or pd.isna(html_content):\n",
    "        return \"\"\n",
    "    \n",
    "    try:\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        \n",
    "        # Remover elementos no deseados\n",
    "        for element in soup(['script', 'style', 'meta', 'link', 'head', 'noscript', 'iframe']):\n",
    "            element.decompose()\n",
    "        \n",
    "        # Remover comentarios y doctypes\n",
    "        for comment in soup.find_all(string=lambda text: isinstance(text, Comment)):\n",
    "            comment.extract()\n",
    "        \n",
    "        for doctype in soup.find_all(string=lambda text: isinstance(text, Doctype)):\n",
    "            doctype.extract()\n",
    "        \n",
    "        # Simplificar etiquetas conservando solo atributos esenciales\n",
    "        for tag in soup.find_all(True):\n",
    "            # Conservar solo estas etiquetas b√°sicas\n",
    "            allowed_tags = ['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', \n",
    "                            'ul', 'ol', 'li', 'a', 'strong', 'em', 'b', 'i',\n",
    "                            'table', 'tr', 'td', 'th', 'div', 'span', 'br', 'hr']\n",
    "            \n",
    "            if tag.name not in allowed_tags:\n",
    "                tag.unwrap()  # Conserva el contenido pero elimina la etiqueta\n",
    "                continue\n",
    "                \n",
    "            # Mantener solo estos atributos (opcional)\n",
    "            allowed_attrs = ['href']\n",
    "            attrs = {}\n",
    "            for attr in allowed_attrs:\n",
    "                if attr in tag.attrs:\n",
    "                    attrs[attr] = tag.attrs[attr]\n",
    "            tag.attrs = attrs\n",
    "            \n",
    "            # Eliminar estilos en l√≠nea\n",
    "            if 'style' in tag.attrs:\n",
    "                del tag.attrs['style']\n",
    "        \n",
    "        # Simplificar estructura\n",
    "        for tag in soup.find_all(['div', 'span']):\n",
    "            tag.unwrap()\n",
    "        \n",
    "        # Reducir espacios innecesarios\n",
    "        output = str(soup)\n",
    "        output = re.sub(r'\\n\\s+', '\\n', output)  # Eliminar espacios m√∫ltiples\n",
    "        output = re.sub(r'\\n{3,}', '\\n\\n', output)  # Reducir saltos de l√≠nea m√∫ltiples\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error simplificando HTML: {e}\")\n",
    "        # Devolver versi√≥n truncada como fallback\n",
    "        return html_content[:5000] + \" [HTML SIMPLIFICADO]\"\n",
    "\n",
    "def create_db_engine(user, password, host, db_name):\n",
    "    \"\"\"Crea un motor de conexi√≥n SQLAlchemy.\"\"\"\n",
    "    # Codifica la contrase√±a si contiene caracteres especiales\n",
    "    password_encoded = quote_plus(password)\n",
    "    connection_string = f\"mysql+mysqlconnector://{user}:{password_encoded}@{host}/{db_name}\"\n",
    "    return create_engine(connection_string)\n",
    "\n",
    "\n",
    "def slugify(text):\n",
    "    \"\"\"Convierte un texto en un slug limpio, ideal para URLs.\"\"\"\n",
    "    text = re.sub(r'[^\\w\\s-]', '', text)  # Elimina caracteres especiales\n",
    "    return re.sub(r'[-\\s]+', '-', text.lower()).strip('-_')\n",
    "\n",
    "def load_prompt_template(filepath=\"promptproject2.txt\"):\n",
    "    \"\"\"Carga la plantilla del prompt desde un archivo.\"\"\"\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "\n",
    "# --- FASE 1: EXTRACCI√ìN ---\n",
    "\n",
    "# def extract_from_old_db():\n",
    "#     \"\"\"Extrae los datos de la tabla 'pages' de la BD antigua.\"\"\"\n",
    "#     print(\"Iniciando Fase 1: Extracci√≥n de datos...\")\n",
    "#     engine_old = create_db_engine(DB_OLD_USER, DB_OLD_PASS, DB_OLD_HOST, DB_OLD_NAME)\n",
    "    \n",
    "#     # Columnas exactas que solicitaste\n",
    "#     query = \"\"\"\n",
    "#     SELECT \n",
    "#         id, title, excerpt, body, meta_description, \n",
    "#         `IFRAME`, `IFRAMEES`, video, videoes, summary_es,\n",
    "#         summary, problem, solution, longterm\n",
    "#     FROM pages\n",
    "#     WHERE layout = 'campaign';\n",
    "#     \"\"\"\n",
    "    \n",
    "#     try:\n",
    "#         df = pd.read_sql(query, engine_old)\n",
    "#         print(f\"‚úÖ Extracci√≥n completada. Se encontraron {len(df)} registros.\")\n",
    "#         return df\n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå Error al extraer datos: {e}\")\n",
    "#         return pd.DataFrame() # Devuelve un DataFrame vac√≠o si falla\n",
    "\n",
    "# --- FASE 1: EXTRACCI√ìN (MODIFICADA) ---\n",
    "\n",
    "def get_page_translations(page_id, engine):\n",
    "    \"\"\"Obtiene todas las traducciones para un ID de p√°gina y las pivota a un diccionario.\"\"\"\n",
    "    query = text(\"\"\"\n",
    "        SELECT column_name, value \n",
    "        FROM translations \n",
    "        WHERE table_name = 'pages' AND foreign_key = :page_id AND locale = 'es'\n",
    "    \"\"\")\n",
    "    \n",
    "    # NUEVO: Diccionario para almacenar traducciones de la p√°gina actual\n",
    "    translations = {}\n",
    "    try:\n",
    "        with engine.connect() as connection:\n",
    "            # Ejecutamos la consulta por cada p√°gina\n",
    "            result = connection.execute(query, {'page_id': page_id})\n",
    "            for row in result:\n",
    "                # Mapeamos 'nombre_columna' -> 'valor_traducido'\n",
    "                translations[row.column_name] = row.value\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  No se pudieron obtener traducciones para el ID {page_id}: {e}\")\n",
    "        \n",
    "    return translations\n",
    "\n",
    "\n",
    "def extract_from_old_db():\n",
    "    \"\"\"Extrae datos de 'pages' y A√ëADE las traducciones existentes desde 'translations'.\"\"\"\n",
    "    print(\"Iniciando Fase 1: Extracci√≥n de datos y traducciones...\")\n",
    "    engine_old = create_db_engine(DB_OLD_USER, DB_OLD_PASS, DB_OLD_HOST, DB_OLD_NAME)\n",
    "    \n",
    "    # La consulta a 'pages' sigue siendo la misma\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        id, title, excerpt, body, meta_description, \n",
    "        `IFRAME`, `IFRAMEES`, video, videoes, summary_es,\n",
    "        summary, problem, solution, longterm\n",
    "    FROM pages\n",
    "    WHERE layout = 'campaign';\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_sql(query, engine_old)\n",
    "        print(f\"‚úÖ Extracci√≥n de 'pages' completada. Se encontraron {len(df)} registros.\")\n",
    "        \n",
    "        # NUEVO: Iterar para obtener traducciones de cada p√°gina\n",
    "        translations_list = []\n",
    "        for page_id in df['id']:\n",
    "            translations_list.append(get_page_translations(page_id, engine_old))\n",
    "            \n",
    "        # A√±adimos las traducciones como una nueva columna que contiene un diccionario\n",
    "        df['translations_es'] = translations_list\n",
    "        \n",
    "        print(\"‚úÖ Traducciones asociadas correctamente.\")\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error al extraer datos: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# --- FASE 2: TRANSFORMACI√ìN ---\n",
    "\n",
    "# def process_with_ai(html_content, prompt_template):\n",
    "#     \"\"\"Procesa el contenido HTML con Azure OpenAI para obtener un JSON.\"\"\"\n",
    "#     if not html_content or pd.isna(html_content):\n",
    "#         return json.dumps({\"en\": \"\", \"es\": \"\"})\n",
    "    \n",
    "#     # Limpiar y simplificar HTML\n",
    "#     cleaned_html = clean_html(html_content)\n",
    "    \n",
    "#     # DEBUG: Ver reducci√≥n de tama√±o\n",
    "#     orig_size = len(html_content)\n",
    "#     new_size = len(cleaned_html)\n",
    "#     print(f\"  Reducci√≥n HTML: {orig_size} ‚Üí {new_size} caracteres (-{100*(1-new_size/orig_size):.1f}%)\")\n",
    "    \n",
    "#     # Dividir el prompt en sistema y contenido de usuario\n",
    "#     system_prompt = prompt_template.split(\"---\")[0].strip()\n",
    "#     user_message = f\"CONTENIDO HTML A PROCESAR:\\n{cleaned_html}\"\n",
    "    \n",
    "#     # Llamar a Azure OpenAI\n",
    "#     response_content = call_azure_openai(system_prompt, user_message)\n",
    "    \n",
    "#     if response_content is None:\n",
    "#         error_msg = \"No se pudo obtener respuesta de Azure OpenAI\"\n",
    "#         print(f\"‚ö†Ô∏è {error_msg}\")\n",
    "#         return json.dumps({\"en\": error_msg, \"es\": error_msg})\n",
    "    \n",
    "#     try:\n",
    "#         # Limpiar la respuesta para asegurar que es un JSON v√°lido\n",
    "#         cleaned_response = response_content.strip().replace(\"```json\", \"\").replace(\"```\", \"\")\n",
    "        \n",
    "#         # Valida y carga el JSON\n",
    "#         parsed_json = json.loads(cleaned_response)\n",
    "#         return json.dumps(parsed_json, ensure_ascii=False)\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ö†Ô∏è Error procesando la respuesta de Azure OpenAI: {e}\")\n",
    "#         return json.dumps({\"en\": f\"Error processing: {e}\", \"es\": f\"Error procesando: {e}\"})\n",
    "\n",
    "# def process_with_ai(html_content, prompt_template):\n",
    "#     \"\"\"Procesa el contenido HTML con Azure OpenAI para obtener un JSON.\"\"\"\n",
    "#     if not html_content or pd.isna(html_content):\n",
    "#         return json.dumps({\"en\": \"\", \"es\": \"\"})\n",
    "    \n",
    "#     cleaned_html = clean_html(html_content)\n",
    "#     orig_size = len(html_content)\n",
    "#     new_size = len(cleaned_html)\n",
    "#     print(f\"  Reducci√≥n HTML: {orig_size} ‚Üí {new_size} caracteres (-{100*(1-new_size/orig_size):.1f}%)\")\n",
    "    \n",
    "#     system_prompt = prompt_template.split(\"---\")[0].strip()\n",
    "#     user_message = f\"CONTENIDO HTML A PROCESAR:\\n{cleaned_html}\"\n",
    "    \n",
    "#     response_content = call_azure_openai(system_prompt, user_message)\n",
    "    \n",
    "#     if response_content is None:\n",
    "#         error_msg = \"No se pudo obtener respuesta de Azure OpenAI\"\n",
    "#         print(f\"‚ö†Ô∏è {error_msg}\")\n",
    "#         return json.dumps({\"en\": error_msg, \"es\": error_msg})\n",
    "    \n",
    "#     try:\n",
    "#         # Mejor manejo de posibles bloques de c√≥digo en la respuesta\n",
    "#         cleaned_response = response_content.strip()\n",
    "        \n",
    "#         # Intentar extraer JSON si est√° dentro de un bloque de c√≥digo\n",
    "#         if cleaned_response.startswith(\"```json\") and cleaned_response.endswith(\"```\"):\n",
    "#             cleaned_response = cleaned_response[7:-3].strip()\n",
    "#         elif cleaned_response.startswith(\"```\") and cleaned_response.endswith(\"```\"):\n",
    "#             cleaned_response = cleaned_response[3:-3].strip()\n",
    "        \n",
    "#         # Validar si es JSON v√°lido\n",
    "#         parsed_json = json.loads(cleaned_response)\n",
    "#         return json.dumps(parsed_json, ensure_ascii=False)\n",
    "\n",
    "#     except Exception as e:\n",
    "#         # Guardar respuesta problem√°tica para depuraci√≥n\n",
    "#         error_id = f\"error_{int(time.time())}\"\n",
    "#         with open(f\"{error_id}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "#             f.write(f\"System Prompt: {system_prompt}\\n\\n\")\n",
    "#             f.write(f\"User Message: {user_message[:1000]}...\\n\\n\")\n",
    "#             f.write(f\"Response Content:\\n{response_content}\")\n",
    "        \n",
    "#         print(f\"‚ö†Ô∏è Error procesando respuesta (ID: {error_id}): {e}\")\n",
    "#         return json.dumps({\n",
    "#             \"en\": f\"Error processing content (ref: {error_id})\",\n",
    "#             \"es\": f\"Error procesando contenido (ref: {error_id})\"\n",
    "#         }, ensure_ascii=False)\n",
    "\n",
    "def process_with_ai(content_dict, prompt_template):\n",
    "    \"\"\"Procesa el diccionario de contenidos con Azure OpenAI para obtener un JSON anidado.\"\"\"\n",
    "    # Convertimos el diccionario a un string JSON para enviarlo\n",
    "    user_message = json.dumps(content_dict, ensure_ascii=False)\n",
    "    \n",
    "    system_prompt = prompt_template.split(\"---\")[0].strip()\n",
    "    \n",
    "    response_content = call_azure_openai(system_prompt, user_message)\n",
    "    \n",
    "    if response_content is None:\n",
    "        error_msg = \"No se pudo obtener respuesta de Azure OpenAI\"\n",
    "        # Devolvemos la estructura vac√≠a esperada para no romper el flujo\n",
    "        return {\"summary_data\": {}, \"editor_content\": {}}\n",
    "    \n",
    "    try:\n",
    "        cleaned_response = response_content.strip()\n",
    "        if cleaned_response.startswith(\"```json\"):\n",
    "            cleaned_response = cleaned_response[7:-3].strip()\n",
    "        \n",
    "        parsed_json = json.loads(cleaned_response)\n",
    "        return parsed_json # Devuelve el diccionario Python parseado\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error procesando la respuesta de Azure OpenAI: {e}\")\n",
    "        # Devolvemos la estructura vac√≠a esperada\n",
    "        return {\"summary_data\": {}, \"editor_content\": {}}\n",
    "\n",
    "# def transform_data(df):\n",
    "#     \"\"\"Transforma el DataFrame extra√≠do al formato de la nueva tabla 'projects'.\"\"\"\n",
    "#     print(\"\\nIniciando Fase 2: Transformaci√≥n de datos...\")\n",
    "    \n",
    "#     if df.empty:\n",
    "#         print(\"No hay datos para transformar.\")\n",
    "#         return []\n",
    "#     # Limit\n",
    "#     # df = df.iloc[0:1]\n",
    "\n",
    "#     prompt_template = load_prompt_template()\n",
    "    \n",
    "#     transformed_records = []\n",
    "    \n",
    "#     for index, row in df.iterrows():\n",
    "#         print(f\"  Procesando registro {index + 1}/{len(df)} (ID antiguo: {row['id']})...\")\n",
    "        \n",
    "#         text_editor_content_json = process_with_ai(row['body'], prompt_template)\n",
    "        \n",
    "#         # Mapea los campos antiguos a la nueva estructura JSON de Laravel\n",
    "#         record = {\n",
    "#             \"slug\": json.dumps({\"en\": slugify(row.get('title', '')), \"es\": slugify(row.get('title', ''))}, ensure_ascii=False), # Asumiendo el mismo slug\n",
    "#             \"title\": json.dumps({\"en\": row.get('title', ''), \"es\": row.get('title', '')}, ensure_ascii=False), # Placeholder, puedes querer traducir el es\n",
    "#             \"excerpt\": json.dumps({\"en\": row.get('excerpt', ''), \"es\": row.get('summary_es', '')}, ensure_ascii=False),\n",
    "#             \"donation_iframe\": json.dumps({\"en\": row.get('IFRAME', ''), \"es\": row.get('IFRAMEES', '')}, ensure_ascii=False),\n",
    "#             \"video_iframe\": json.dumps({\"en\": row.get('video', ''), \"es\": row.get('videoes', '')}, ensure_ascii=False),\n",
    "#             \"meta\": json.dumps({\"en\": row.get('meta_description', ''), \"es\": \"\"}, ensure_ascii=False), # Placeholder para meta en espa√±ol\n",
    "#             \"content\": STATIC_CONTENT_JSON,\n",
    "#             \"text_editor_content\": text_editor_content_json,\n",
    "#             \"status\": \"draft\", # Valor por defecto seg√∫n la migraci√≥n\n",
    "#             \"user_id\": 1, # ¬°IMPORTANTE! Asigna el ID de usuario correcto\n",
    "#             \"social_links\": json.dumps({}), # Placeholder\n",
    "#             # timestamps (created_at, updated_at) son manejados por Laravel/MySQL\n",
    "#         }\n",
    "#         transformed_records.append(record)\n",
    "        \n",
    "#     print(\"‚úÖ Transformaci√≥n completada.\")\n",
    "#     return transformed_records\n",
    "\n",
    "# databasemigrationprojects.ipynb\n",
    "\n",
    "# def transform_data(df):\n",
    "#     \"\"\"Transforma el DataFrame extra√≠do al formato de la nueva tabla 'projects'.\"\"\"\n",
    "#     print(\"\\nIniciando Fase 2: Transformaci√≥n de datos...\")\n",
    "#     if df.empty:\n",
    "#         return []\n",
    "    \n",
    "#     df = df.iloc[0:2]\n",
    "\n",
    "#     prompt_template = load_prompt_template()\n",
    "#     transformed_records = []\n",
    "    \n",
    "#     for index, row in df.iterrows():\n",
    "#         print(f\"  Procesando registro {index + 1}/{len(df)} (ID antiguo: {row['id']})...\")\n",
    "        \n",
    "#         # 1. Unificar el contenido de entrada para la IA\n",
    "#         input_content_for_ai = {\n",
    "#             \"summary\": row.get('summary', ''),\n",
    "#             \"body\": row.get('body', ''),\n",
    "#             \"problem\": row.get('problem', ''),\n",
    "#             \"solution\": row.get('solution', ''),\n",
    "#             \"longterm\": row.get('longterm', '')\n",
    "#         }\n",
    "        \n",
    "#         # 2. Llamar a la IA para obtener la estructura anidada\n",
    "#         ai_response = process_with_ai(input_content_for_ai, prompt_template)\n",
    "        \n",
    "#         # 3. Extraer las partes de la respuesta de la IA de forma segura\n",
    "#         summary_data = ai_response.get('summary_data', {})\n",
    "#         editor_content = ai_response.get('editor_content', {})\n",
    "\n",
    "#         # 4. Preparar la estructura 'content' final\n",
    "#         # Hacemos una copia profunda para no modificar la plantilla original\n",
    "#         final_content_structure = json.loads(json.dumps(STATIC_CONTENT_STRUCTURE))\n",
    "\n",
    "#         # Inyectar el summary en ingl√©s, con valores por defecto\n",
    "#         summary_en = summary_data.get('en', {})\n",
    "#         final_content_structure['en']['summary_title'] = summary_en.get('title') or \"Summary\"\n",
    "#         final_content_structure['en']['summary_text'] = summary_en.get('text', '')\n",
    "\n",
    "#         # Inyectar el summary en espa√±ol, con valores por defecto\n",
    "#         summary_es = summary_data.get('es', {})\n",
    "#         final_content_structure['es']['summary_title'] = summary_es.get('title') or \"Resumen\"\n",
    "#         final_content_structure['es']['summary_text'] = summary_es.get('text', '')\n",
    "\n",
    "#         # 5. Mapear todos los campos para el registro final de la BD\n",
    "#         record = {\n",
    "#             \"slug\": json.dumps({\"en\": slugify(row.get('title', '')), \"es\": slugify(row.get('title', ''))}, ensure_ascii=False),\n",
    "#             \"title\": json.dumps({\"en\": row.get('title', ''), \"es\": row.get('title', '')}, ensure_ascii=False),\n",
    "#             \"excerpt\": json.dumps({\"en\": row.get('excerpt', ''), \"es\": row.get('summary_es', '')}, ensure_ascii=False),\n",
    "#             \"donation_iframe\": json.dumps({\"en\": row.get('IFRAME', ''), \"es\": row.get('IFRAMEES', '')}, ensure_ascii=False),\n",
    "#             \"video_iframe\": json.dumps({\"en\": row.get('video', ''), \"es\": row.get('videoes', '')}, ensure_ascii=False),\n",
    "#             \"meta\": json.dumps({\"en\": row.get('meta_description', ''), \"es\": \"\"}, ensure_ascii=False),\n",
    "            \n",
    "#             # Columnas con la nueva l√≥gica\n",
    "#             \"content\": json.dumps(final_content_structure, ensure_ascii=False),\n",
    "#             \"text_editor_content\": json.dumps(editor_content, ensure_ascii=False),\n",
    "            \n",
    "#             \"status\": \"draft\",\n",
    "#             \"user_id\": 1,\n",
    "#             \"social_links\": json.dumps({}),\n",
    "#         }\n",
    "#         transformed_records.append(record)\n",
    "        \n",
    "#     print(\"‚úÖ Transformaci√≥n completada.\")\n",
    "#     return transformed_records\n",
    "\n",
    "# --- FASE 2: TRANSFORMACI√ìN (MODIFICADA) ---\n",
    "\n",
    "def transform_data(df):\n",
    "    \"\"\"Transforma el DataFrame usando las traducciones existentes y el nuevo prompt.\"\"\"\n",
    "    print(\"\\nIniciando Fase 2: Transformaci√≥n de datos...\")\n",
    "    if df.empty:\n",
    "        return []\n",
    "    \n",
    "    # Puedes quitar o modificar este l√≠mite para procesar todos los registros\n",
    "   \n",
    "\n",
    "    prompt_template = load_prompt_template()\n",
    "    transformed_records = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        print(f\"  Procesando registro {index + 1}/{len(df)} (ID antiguo: {row['id']})...\")\n",
    "        \n",
    "        # MODIFICADO: Ahora 'translations_es' es un diccionario con las traducciones\n",
    "        translations = row.get('translations_es', {})\n",
    "\n",
    "        # 1. Unificar contenido para la IA, ahora con ambos idiomas\n",
    "        input_content_for_ai = {\n",
    "            \"summary\": {\n",
    "                \"en\": row.get('summary', ''),\n",
    "                # Usamos la traducci√≥n si existe, si no, el original como fallback\n",
    "                \"es\": translations.get('summary', row.get('summary', '')) \n",
    "            },\n",
    "            \"body\": {\n",
    "                \"en\": row.get('body', ''),\n",
    "                \"es\": translations.get('body', row.get('body', ''))\n",
    "            },\n",
    "            \"problem\": {\n",
    "                \"en\": row.get('problem', ''),\n",
    "                \"es\": translations.get('problem', row.get('problem', ''))\n",
    "            },\n",
    "            \"solution\": {\n",
    "                \"en\": row.get('solution', ''),\n",
    "                \"es\": translations.get('solution', row.get('solution', ''))\n",
    "            },\n",
    "            \"longterm\": {\n",
    "                \"en\": row.get('longterm', ''),\n",
    "                \"es\": translations.get('longterm', row.get('longterm', ''))\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # 2. Llamar a la IA (la funci√≥n no cambia, solo el input que le damos)\n",
    "        ai_response = process_with_ai(input_content_for_ai, prompt_template)\n",
    "        \n",
    "        # 3. Extraer partes de la respuesta (la funci√≥n no cambia)\n",
    "        summary_data = ai_response.get('summary_data', {})\n",
    "        editor_content = ai_response.get('editor_content', {})\n",
    "\n",
    "        # 4. Preparar la estructura 'content' final (la l√≥gica de inyecci√≥n no cambia)\n",
    "        final_content_structure = json.loads(json.dumps(STATIC_CONTENT_STRUCTURE))\n",
    "        summary_en = summary_data.get('en', {})\n",
    "        final_content_structure['en']['summary_title'] = summary_en.get('title') or \"Summary\"\n",
    "        final_content_structure['en']['summary_text'] = summary_en.get('text', '')\n",
    "        summary_es = summary_data.get('es', {})\n",
    "        final_content_structure['es']['summary_title'] = summary_es.get('title') or \"Resumen\"\n",
    "        final_content_structure['es']['summary_text'] = summary_es.get('text', '')\n",
    "\n",
    "        # 5. MODIFICADO: Mapear campos usando las traducciones existentes\n",
    "        record = {\n",
    "            # Usamos el slug original y el traducido si existe\n",
    "            \"slug\": json.dumps({\n",
    "                \"en\": slugify(row.get('title', '')), \n",
    "                \"es\": slugify(translations.get('slug', row.get('title', '')))\n",
    "            }, ensure_ascii=False),\n",
    "            \"title\": json.dumps({\n",
    "                \"en\": row.get('title', ''), \n",
    "                \"es\": translations.get('title', row.get('title', ''))\n",
    "            }, ensure_ascii=False),\n",
    "            \"excerpt\": json.dumps({\n",
    "                \"en\": row.get('excerpt', ''), \n",
    "                \"es\": translations.get('excerpt', row.get('summary_es', ''))\n",
    "            }, ensure_ascii=False),\n",
    "            \"donation_iframe\": json.dumps({\n",
    "                \"en\": row.get('IFRAME', ''), \n",
    "                \"es\": row.get('IFRAMEES', '')\n",
    "            }, ensure_ascii=False),\n",
    "            \"video_iframe\": json.dumps({\n",
    "                \"en\": row.get('video', ''), \n",
    "                \"es\": row.get('videoes', '')\n",
    "            }, ensure_ascii=False),\n",
    "            \"meta\": json.dumps({\n",
    "                \"en\": row.get('meta_description', ''), \n",
    "                \"es\": translations.get('meta_description', '')\n",
    "            }, ensure_ascii=False),\n",
    "            \n",
    "            \"content\": json.dumps(final_content_structure, ensure_ascii=False),\n",
    "            \"text_editor_content\": json.dumps(editor_content, ensure_ascii=False),\n",
    "            \n",
    "            \"status\": \"draft\",\n",
    "            \"user_id\": 1,\n",
    "            \"social_links\": json.dumps({}),\n",
    "        }\n",
    "        transformed_records.append(record)\n",
    "        \n",
    "    print(\"‚úÖ Transformaci√≥n completada.\")\n",
    "    return transformed_records\n",
    "\n",
    "\n",
    "# --- FASE 3: CARGA ---\n",
    "\n",
    "def load_into_new_db(records):\n",
    "    \"\"\"Carga los registros transformados en la nueva base de datos.\"\"\"\n",
    "    print(\"\\nIniciando Fase 3: Carga de datos...\")\n",
    "    \n",
    "    if not records:\n",
    "        print(\"No hay registros para cargar.\")\n",
    "        return\n",
    "\n",
    "    engine_new = create_db_engine(DB_NEW_USER, DB_NEW_PASS, DB_NEW_HOST, DB_NEW_NAME)\n",
    "    \n",
    "    # La migraci√≥n define las columnas de la tabla 'projects'\n",
    "    insert_query = text(\"\"\"\n",
    "    INSERT INTO projects (\n",
    "        slug, title, excerpt, donation_iframe, video_iframe, content, text_editor_content, meta, \n",
    "        status, user_id, social_links, created_at, updated_at\n",
    "    )\n",
    "    SELECT :slug, :title, :excerpt, :donation_iframe, :video_iframe, :content, :text_editor_content, :meta, \n",
    "           :status, :user_id, :social_links, NOW(), NOW()\n",
    "    WHERE NOT EXISTS (\n",
    "        SELECT 1 FROM projects WHERE slug = :slug\n",
    "    )\n",
    "\"\"\")\n",
    "    \n",
    "    try:\n",
    "        with engine_new.connect() as connection:\n",
    "            for record in records:\n",
    "                connection.execute(insert_query, record)\n",
    "            connection.commit() # Confirma la transacci√≥n\n",
    "        print(f\"‚úÖ Carga completada. Se han insertado {len(records)} registros en la tabla 'projects'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error al cargar datos: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "46c5b189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Prueba\")\n",
    "    \n",
    "#     # Paso 1: Extraer\n",
    "# data_to_migrate = extract_from_old_db()\n",
    "\n",
    "# test_row = data_to_migrate.iloc[0:3]\n",
    "# response_content = call_azure_openai(\n",
    "#     system_prompt, \n",
    "#     f\"CONTENIDO HTML A PROCESAR:\\n{clean_html(test_row['body'])}\"\n",
    "# )\n",
    "# print(\"Respuesta cruda de Azure OpenAI:\")\n",
    "# print(response_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9cce7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Iniciando script de migraci√≥n de 'pages' a 'projects'.\n",
      "Iniciando Fase 1: Extracci√≥n de datos y traducciones...\n",
      "‚úÖ Extracci√≥n de 'pages' completada. Se encontraron 10 registros.\n",
      "‚úÖ Traducciones asociadas correctamente.\n",
      "\n",
      "Iniciando Fase 2: Transformaci√≥n de datos...\n",
      "  Procesando registro 1/10 (ID antiguo: 7)...\n",
      "‚ö†Ô∏è Error procesando la respuesta de Azure OpenAI: Invalid control character at: line 13 column 2867 (char 4386)\n",
      "  Procesando registro 2/10 (ID antiguo: 12)...\n",
      "üîÅ Esperando 47 segundos por l√≠mite de tasa (429)...\n",
      "  Procesando registro 3/10 (ID antiguo: 13)...\n",
      "  Procesando registro 4/10 (ID antiguo: 14)...\n",
      "  Procesando registro 5/10 (ID antiguo: 15)...\n",
      "üîÅ Esperando 29 segundos por l√≠mite de tasa (429)...\n",
      "  Procesando registro 6/10 (ID antiguo: 16)...\n",
      "  Procesando registro 7/10 (ID antiguo: 17)...\n",
      "üîÅ Esperando 35 segundos por l√≠mite de tasa (429)...\n",
      "  Procesando registro 8/10 (ID antiguo: 20)...\n",
      "‚ö†Ô∏è Error procesando la respuesta de Azure OpenAI: Invalid control character at: line 14 column 964 (char 4349)\n",
      "  Procesando registro 9/10 (ID antiguo: 29)...\n",
      "  Procesando registro 10/10 (ID antiguo: 30)...\n",
      "‚úÖ Transformaci√≥n completada.\n",
      "\n",
      "Iniciando Fase 3: Carga de datos...\n",
      "‚úÖ Carga completada. Se han insertado 10 registros en la tabla 'projects'.\n",
      "\n",
      "Proceso finalizado\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"üöÄ Iniciando script de migraci√≥n de 'pages' a 'projects'.\")\n",
    "    \n",
    "    # Paso 1: Extraer\n",
    "data_to_migrate = extract_from_old_db()\n",
    "\n",
    "\n",
    "# data_to_migrate.head(12)\n",
    "    # Paso 2: Transformar\n",
    "transformed_data = transform_data(data_to_migrate)\n",
    "    \n",
    "    # Paso 3: Cargar\n",
    "load_into_new_db(transformed_data)\n",
    "    \n",
    "print(\"\\nProceso finalizado\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
